<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ilya Pimenov - Unzip files on S3, concatenate, gzip and put on Google Cloud Storage</title>
  <meta name="author" content="Ilya Pimenov" />
  <meta name="description" content="The blog of Ilya Pimenov" />
  <link rel="canonical" href="http://ilyapimenov.com/blog/2014/11/12/unzip-files-on-s3-concatenate-gzip-and-put-on-gs.html" />

  <!-- <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet" type="text/css"> -->
  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="/favicon.png">
  <link rel="alternate" type="application/rss+xml" title="Ilya Pimenov" href="http://ilyapimenov.com/atom.xml" />

  <link rel="stylesheet" href="/assets/css/all.css">
<!--[if IE 7]>
  <link rel="stylesheet" href="/assets/css/font-awesome-ie7.min.css">
<![endif]-->
</head>
<body>
  <div class="container">
    <div class="four columns sidebar">
      <nav>
  <h1>Hi,</h1>
  <a href="/">
<!--     <img src="/logo.png" id="logo" alt="Blog logo"/> -->
    <img src="//2.gravatar.com/avatar/637a92c02ed1605df97e8c16cbfaad7e?&r=x&s=240" id="logo" alt="Blog logo"/>
  </a>
  <h2>I'm <a href="/">Ilya Pimenov</a>.</h2>
  <hr/>
  <ul>
  <p>28 y/o hacker with extensive interest in high load software, big data, deep app integration and SaaS solutions.</p>
  <p>Currently casting spells at <a href="http://ebay.nl/">eBay</a>.</p>
  <hr/>
  <div>
    <div id="social">
      Follow me:
<div id="stalker">
  
  <a title="ilya-pi on Github" href="http://github.com/ilya-pi">
    <i class="icon-github-sign"></i>
  </a>
  

  
  <a title="ilya-pi on Hacker News" href="http://news.ycombinator.com/user?id=ilya-pi">
    <i class="icon-sign-blank"></i>
    <span class="icon-overlay icon-hn">Y</span>
  </a>
  

  

  <a title="RSS feed" id="rss" href="/atom.xml">
    <i class="icon-rss-sign"></i>
  </a>
</div>
    </div>
  </div>
  </ul>
</nav>
    </div>

    <div class="eleven columns content">
      <p class="meta">
  November 12, 2014 
  <a href="/">
    <i class="home icon-home"></i>
  </a>
</p>

<h1 class="title">Unzip files on S3, concatenate, gzip and put on Google Cloud Storage</h1>

<div id="post">
  <p><em>Now this is not such a big task, yet it took me surprisingly long time, therefore I’ve decided to write this.</em></p>

<p>What happens — we have these huge zipped log files for analysis in our <a href="http://aws.amazon.com/s3‎">Amazon S3</a> bucket on Amazon and we wanted to try processing them on <a href="https://cloud.google.com/bigquery">Google Big Query</a>, which supports only gzip as a matter of compression.</p>

<p>Overall — zip is a bad format when it comes to big data, the following <a href="https://issues.apache.org/jira/browse/MAPREDUCE-210">issue</a> — <em>“want InputFormat for zip files”</em> been in progress with <em>major</em> priority for the past <strong>7 years</strong>.</p>

<p>Cascading had a support for ZIP sometime back, but it was removed in later releases. Please reference the issue thread for reasoning on the topic.</p>

<p>Nevertheless, we have about 2k+ files, 250Mb average size in ZIP, that we’d love to see ready for analysis and further processing in BigQuery. Which leaves you with <strong>0.5 Terabyte</strong> to copy, unzip, gzip and upload.</p>

<h1 id="unzip-files-on-s3-concat-and-save-in-gzip">Unzip files on S3, concat and save in gzip</h1>

<p>For this reason it calls for some hadoopy solution, and luckily enough there is just one — <a href="http://hadoop.apache.org/docs/r1.2.1/streaming.html">Hadoop Streaming</a>. Combining it together with ZipStream <a href="https://bitbucket.org/tebeka/zipstream">library</a> written by Miki Tebeka:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># /opt/hadoop/bin/hadoop jar /opt/hadoop-1.2.1/contrib/streaming/hadoop-streaming-1.2.1.jar -libjars zipstream-1.1-SNAPSHOT.jar -mapper /bin/cat -reducer /bin/cat -inputformat com.mikitebeka.mapred.ZipInputFormat -input s3n://screen6-zip-bucket -output s3n://screen6-gzip-bucket/result</span></code></pre></div>

<p><strong>Note:</strong> Be sure to use some a path with a bucket name, like <code>-output s3n://screen6-gzip-bucket/result</code>, not <code>-output s3n://screen6-gzip-bucket/</code>; streaming utility silently fails on those with only one error message: <code>Streaming Command Failed!</code>.</p>

<p>We also enabled the following options that were particularly usefull:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Option</th>
      <th style="text-align: center">Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">-D mapred.output.compress=true</td>
      <td style="text-align: center">Enable compression</td>
    </tr>
    <tr>
      <td style="text-align: center">-D mapred.output.compression.codec = org.apache.hadoop.io.compress.GzipCodec</td>
      <td style="text-align: center">Use gzip for compression</td>
    </tr>
    <tr>
      <td style="text-align: center">-D mapred.max.map.failures.percent=10</td>
      <td style="text-align: center">Allow 10% map job to fail. Files are sent in by third parties and it’s not uncommon to see that some are corrupted</td>
    </tr>
  </tbody>
</table>

<p>Combining that together with a wrapper script that will use a file as a source of input files <code>process-zips.sh</code>:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#!/bin/bash</span>

<span class="c"># Pass in $1 file with all the s3 paths you wish to process</span>
<span class="c"># like:</span>
<span class="c"># s3n://mybucket/file1</span>
<span class="c"># s3n://mybucket/file1</span>
<span class="c"># ...</span>
<span class="c"># $2 number of lines per one job</span>

<span class="c"># Create new file handle 5</span>
<span class="nb">exec </span>5&lt; <span class="nv">$1</span>

<span class="c"># Step counter</span>
<span class="nv">n</span><span class="o">=</span>0

<span class="c"># Now you can use &quot;&lt;&amp;5&quot; to read from this file</span>
<span class="k">while</span> <span class="nb">read </span>lines &lt;<span class="p">&amp;</span><span class="m">5</span> <span class="p">;</span> <span class="k">do</span>
	<span class="k">for</span> i in <span class="k">$(</span>seq <span class="m">1</span> <span class="nv">$2</span><span class="k">)</span> <span class="p">;</span> <span class="k">do</span> <span class="nb">read </span>line &lt;<span class="p">&amp;</span>5<span class="p">;</span> lines+<span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="nv">$line</span> <span class="p">;</span> <span class="k">done</span>

	nohup /opt/hadoop/bin/hadoop jar /opt/hadoop-1.2.1/contrib/streaming/hadoop-streaming-1.2.1.jar -libjars zipstream-1.1-SNAPSHOT.jar -D mapred.max.map.failures.percent<span class="o">=</span><span class="m">25</span> -D mapred.output.compress<span class="o">=</span><span class="nb">true</span> -D mapred.output.compression.codec<span class="o">=</span>org.apache.hadoop.io.compress.GzipCodec -mapper /bin/cat -reducer /bin/cat -inputformat com.mikitebeka.mapred.ZipInputFormat -input <span class="nv">$lines</span> -output s3n://screen6-gzip/<span class="nv">$1</span>-part<span class="nv">$n</span> &gt;<span class="nv">$1</span>-part<span class="nv">$n</span>.log 2&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">&amp;</span>

	<span class="nv">n</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$n</span> + 1<span class="sb">`</span>
<span class="k">done</span>

<span class="c"># Close file handle 5</span>
<span class="nb">exec </span>5&lt;<span class="p">&amp;</span>-
<span class="nb">echo</span> <span class="s2">&quot;Finished in $n$ parts&quot;</span></code></pre></div>

<p>Launch with:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>./process-zips.sh fileA 10</code></pre></div>

<p>and then enjoy it with:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>tail -F fileA-part*

<span class="o">==</span>&gt; part8.log &lt;<span class="o">==</span>


<span class="o">==</span>&gt; fileA-part15.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar2317634900187317714/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob4578016248914426911.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part10.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar619398222690999006/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob5237043347834171306.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part16.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar5691853025461419129/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob2661134060791365061.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part13.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar6780268392176885393/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob7066625037729937192.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part17.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar1819205972838198675/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob4559632407084620827.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part9.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar2117775095566780310/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob2182082276684486804.jar <span class="nv">tmpDir</span><span class="o">=</span><span class="nv">null</span>

<span class="o">==</span>&gt; fileA-part12.log &lt;<span class="o">==</span>
packageJobJar: <span class="o">[</span>/mnt/hadoop/hadoop-hduser/hadoop-unjar7321821655058192548/<span class="o">]</span> <span class="o">[]</span> /tmp/streamjob7774227815593783167.jar <span class="nv">tmpDir</span><span class="o">=</span>null</code></pre></div>

<h1 id="copy-to-google-cloud-storage">Copy to Google Cloud Storage</h1>

<p>In order to move data from S3 or HDFS to Google Cloud Storage (<code>gs://</code>) we’ll utilize another hadoop-family tool that’s been around for some time — <a href="http://hadoop.apache.org/docs/r0.19.0/distcp.html">distcp</a>.</p>

<p>First of all you will need to configure the Google Cloud Storage Connector for Hadoop, in order to do so, please follow this <a href="https://cloud.google.com/hadoop/google-cloud-storage-connector">guide</a>.</p>

<p>Once it’s done, should be as simple as:</p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># /opt/hadoop/bin/hadoop distcp2 s3n://my/bucket/here gs://my/bucket/there</span></code></pre></div>

<p><strong>Note:</strong> Be sure to use <code>distcp2</code> instead of <code>distcp</code>. For whatever the reason <code>distcp</code> doesn’t correctly resolve the classpath, no matter what you do and you are very likely to end up with:</p>

<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">RuntimeException</span><span class="o">:</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">ClassNotFoundException</span><span class="o">:</span> <span class="n">com</span><span class="o">.</span><span class="na">google</span><span class="o">.</span><span class="na">cloud</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">gcs</span><span class="o">.</span><span class="na">GoogleHadoopFileSystem</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">conf</span><span class="o">.</span><span class="na">Configuration</span><span class="o">.</span><span class="na">getClass</span><span class="o">(</span><span class="n">Configuration</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">857</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileSystem</span><span class="o">.</span><span class="na">createFileSystem</span><span class="o">(</span><span class="n">FileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1440</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileSystem</span><span class="o">.</span><span class="na">access$200</span><span class="o">(</span><span class="n">FileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">67</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileSystem$Cache</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">FileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1464</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileSystem</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">FileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">263</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">Path</span><span class="o">.</span><span class="na">getFileSystem</span><span class="o">(</span><span class="n">Path</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">187</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">.</span><span class="na">JobHistory$JobInfo</span><span class="o">.</span><span class="na">logSubmitted</span><span class="o">(</span><span class="n">JobHistory</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1761</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">.</span><span class="na">JobInProgress$3</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">JobInProgress</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">709</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">security</span><span class="o">.</span><span class="na">AccessController</span><span class="o">.</span><span class="na">doPrivileged</span><span class="o">(</span><span class="n">Native</span> <span class="n">Method</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">javax</span><span class="o">.</span><span class="na">security</span><span class="o">.</span><span class="na">auth</span><span class="o">.</span><span class="na">Subject</span><span class="o">.</span><span class="na">doAs</span><span class="o">(</span><span class="n">Subject</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">415</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">security</span><span class="o">.</span><span class="na">UserGroupInformation</span><span class="o">.</span><span class="na">doAs</span><span class="o">(</span><span class="n">UserGroupInformation</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1190</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">.</span><span class="na">JobInProgress</span><span class="o">.</span><span class="na">initTasks</span><span class="o">(</span><span class="n">JobInProgress</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">706</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">.</span><span class="na">JobTracker</span><span class="o">.</span><span class="na">initJob</span><span class="o">(</span><span class="n">JobTracker</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">3890</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">mapred</span><span class="o">.</span><span class="na">EagerTaskInitializationListener$InitJob</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">EagerTaskInitializationListener</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">79</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">ThreadPoolExecutor</span><span class="o">.</span><span class="na">runWorker</span><span class="o">(</span><span class="n">ThreadPoolExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1145</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">ThreadPoolExecutor$Worker</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">ThreadPoolExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">615</span><span class="o">)</span>
	<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Thread</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">Thread</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">745</span><span class="o">)</span></code></pre></div>

<p>Voilà</p>

<h1 id="links">Links</h1>

<ol>
  <li><a href="http://hadoop.apache.org/docs/r1.2.1/streaming.html">Hadoop Streaming utility</a></li>
  <li><a href="https://bitbucket.org/tebeka/zipstream">ZipStream library</a></li>
  <li><a href="http://hadoop.apache.org/docs/r0.19.0/distcp.html">Hadoop Distributed Copy</a></li>
  <li><a href="https://cloud.google.com/hadoop/google-cloud-storage-connector">Google cloud storage connector</a></li>
</ol>

<p><em>[Originally published in <a href="http://techblog.s6.io/blog/2014/11/12/unzip-files-on-s3-concatenate-gzip-and-put-on-gs.html">Screen6 Technical Blog</a> on 11/12/2014]</em></p>

</div>


<div id="author">
  by <a href="http://ilyapimenov.com/">Ilya Pimenov</a>
</div>



    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'ilya-pi'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>    


<hr>

<div id="related">
  <h3>Related Posts</h3>
  <ul class="posts">
    
    
    <li>
      <span>19 Jan 2015 &raquo;</span> <a href="/blog/2015/01/19/ftp-proxy-to-gcs.html">FTP Proxy to Google Cloud Storage</a>
    </li>
    
    
    
    <li>
      <span>19 Sep 2014 &raquo;</span> <a href="/blog/2014/09/19/lua-scripts-in-redis-within-nodejs.html">Lua scripts in Redis within Node.js</a>
    </li>
    
    
    
    <li>
      <span>14 Nov 2013 &raquo;</span> <a href="/blog/2013/11/14/hyperloglog-with-cascalog.html">HyperLogLog with Cascalog</a>
    </li>
    
    
  </ul>
</div>
    
      <div class="footer">
        <div class="disclaimer">
  <p>
    
        The postings on this site are my own and don't necessarily represent my employer’s positions, strategies or opinions.<br/>
    

    © Ilya Pimenov, 2013-2015 &mdash; built with Jekyll using Lagom theme
  </p>
</div>
      </div>
    </div>
  </div>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64421368-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>